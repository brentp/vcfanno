{
    "docs": [
        {
            "location": "/", 
            "text": "vcfanno\n\n\n\n\n\n\n\n\n\nMailing List\n\n\nvcfanno annotates a VCF with any number of \nsorted\n and tabixed input BED, BAM, and VCF files in parallel.\nIt does this by finding overlaps as it streams over the data and applying\nuser-defined operations on the overlapping annotations.\n\n\nIn order to parallelize, work is broken down as follows. A slice (array) of query intervals is accumulated \nuntil a specified number is reached (usually ~5K-25K) or a gap cutoff is exceeded; at that point, the\nbounds of the region are used to perform a tabix (or any regional) query on the database files. This is\nall done in \nirelate\n. \nvcfanno\n then iterates over the streams that\nresult from the tabix queries and finds intersections with the query stream. This is a parallel chrom-sweep.\nThis method avoids problems with chromosome order.\n\n\nFor VCF, values are pulled by name from the INFO field.\nFor BED, values are pulled from (1-based) column number.\nFor BAM, depth (\ncount\n), \"mapq\" and \"seq\" are currently supported.\n\n\nvcfanno\n is written in \ngo\n and it supports custom user-scripts written in lua.\nIt can annotate more than 8,000 variants per second with 34 annotations from 9 files on a modest laptop and over 30K variants per second using 12 processes on a server.\n\n\nWe are actively developing \nvcfanno\n and appreciate feedback and bug reports.\n\n\nUsage\n\n\nAfter downloading the \nbinary for your system\n (see section below) usage looks like:\n\n\n  ./vcfanno -lua example/custom.lua example/conf.toml example/query.vcf.gz\n\n\n\n\nWhere conf.toml looks like:\n\n\n[[annotation]]\nfile=\nExAC.vcf\n\nfields = [\nAC_AFR\n, \nAC_AMR\n, \nAC_EAS\n]\nops=[\nfirst\n, \nfirst\n, \nmin\n]\n\n[[annotation]]\nfile=\nfitcons.bed\n\ncolumns = [4, 4]\nnames=[\nfitcons_mean\n, \nlua_sum\n]\n# note the 2nd op here is lua that has access to `vals`\nops=[\nmean\n, \nlua:function sum(t) local sum = 0; for i=1,#t do sum = sum + t[i] end return sum / #t end\n]\n\n[[annotation]]\nfile=\nexample/ex.bam\n\nnames=[\nex_bam_depth\n]\nfields=[\ndepth\n, \nmapq\n, \nseq\n]\nops=[\ncount\n, \nmean\n, \nconcat\n]\n\n\n\n\nSo from \nExAC.vcf\n we will pull the fields from the info field and apply the corresponding\n\noperation\n from the \nops\n array. Users can add as many \n[[annotation]]\n blocks to the\nconf file as desired. Files can be local as above, or available via http/https.\n\n\nAlso see the additional usage section at the bottom for additional details.\n\n\nExample\n\n\nthe example directory contains the data and conf for a full example. To run, either download\nthe \nappropriate binary\n for your system\nor build with:\n\n\ngo get\ngo build -o vcfanno\n\n\n\n\nfrom this directory.\nThen, you can annotate with:\n\n\n./vcfanno -p 4 -lua example/custom.lua example/conf.toml example/query.vcf.gz \n annotated.vcf\n\n\n\n\nAn example INFO field row before annotation (pos 98683):\n\n\nAB=0.282443;ABP=56.8661;AC=11;AF=0.34375;AN=32;AO=45;CIGAR=1X;TYPE=snp\n\n\n\n\nand after:\n\n\nAB=0.2824;ABP=56.8661;AC=11;AF=0.3438;AN=32;AO=45;CIGAR=1X;TYPE=snp;AC_AFR=0;AC_AMR=0;AC_EAS=0;fitcons_mean=0.061;lua_sum=0.061\n\n\n\n\nOperations\n\n\nIn most cases, we will have a single annotation entry for each entry (variant)\nin the query VCF. However, it is possible that there will be multiple annotations\nfrom a single annotation file--in this case, the op determines how the many values\nare \nreduced\n. Valid operations are:\n\n\n\n\nlua:$lua // see section below for more details\n\n\nmean\n\n\nmax\n\n\nmin\n\n\nconcat // comma delimited list of output\n\n\ncount  // count the number of overlaps\n\n\nuniq\n\n\nfirst \n\n\nflag   // presense/absence via vcf flag\n\n\n\n\nPostAnnotation\n\n\nOne of the most powerful features of \nvcfanno\n is the embedded scripting language, lua, combined with \npostannotation\n.\n\n[[postannotation]]\n blocks occur after all the annotations have been applied. They are similar, but in the fields\ncolumn, they request a number of columns from the query file (including the new columns added in annotation). For example\nif we have AC and AN columns indicating the alternate count and the number of chromosomes, respectively, we could create\na new allele frequency column, \nAF\n with this block:\n\n\n[[postannotation]]\nfields=[\nAC\n, \nAN\n]\nop=\nlua:AC / AN\n\nname=\nAF\n\ntype=\nFloat\n\n\n\n\n\nwhere the type field is one of the types accepted in VCF format, the \nname\n is the name of the field that is created, the \nfields\n\nindicate the fields (from the INFO) that will be available to the op, and the \nop\n indicates the action to perform. This can be quite\npowerful. For an extensive example that demonstrates the utility of this type of approach, see\n\ndocs/examples/clinvar_exac.md\n.\n\n\nBinaries\n\n\nbinary executables are available \nhere\n\nfor \nlinux\n, \nmac\n (darwin), and \nwindows\n for \n32\n and \n64\n bit platforms.\n\n\nPreprocessing\n\n\nAnnotations will be the most accurate if your query and annotation variants are split (no multiple ALTs) and normalized (left-aligned and trimmed). At some point, this will be done internally, but for now, you can get a split and normalized VCF using \nvt\n\nwith:\n\n\nvt decompose -s $VCF | vt normalize -r $REF - \n $NORM_VCF\n\n\n\n\nvcfanno\n will check all alternates that are present in both the query and the annotations but the decomposition (splitting alts) will allow for better normalization.\n\n\nDevelopment\n\n\nThis, and the associated go libraries (\nvcfgo\n,\n\nirelate\n, \nxopen\n,\n\ngoluaez\n are under active development.\n\n\nAdditional Usage\n\n\n-ends\n\n\nFor annotating large variants, such as CNVs or structural variants (SVs), it can be useful to\nannotate the \nends\n of the variant in addition to the region itself. To do this, specify the \n-ends\n\nflag to \nvcfanno\n. e.g.:\n\n\nvcfanno -ends example/conf.toml example/query.vcf.gz\n\n\n\n\nIn this case, the names field in the \nconf\n file contains, \"fitcons_mean\". The output will contain\n\nfitcons\\_mean\n as before along with \nleft\\_fitcons\\_mean\n and \nright\\_fitcons\\_mean\n for any variants\nthat are longer than 1 base. The \nleft\n end will be for the single-base at the lowest base of the variant\nand the \nright\n end will be for the single base at the higher numbered base of the variant.\n\n\n-permissive-overlap\n\n\nBy default, when annotating with a variant, in addition to the overlap requirement, the variants must share\nthe same position, the same reference allele and at least one alternate allele (this is only used for\nvariants, not for BED/BAM annotations). If this flag is specified, only overlap testing is used and shared\nREF/ALT are not required.\n\n\n-p\n\n\nSet to the number of processes that \nvcfanno\n can use during annotation. \nvcfanno\n parallelizes well\nup to 15 or so cores.\n\n\n-lua\n\n\ncustom in ops (lua). For use when the built-in \nops\n don't supply the needed reduction.\n\n\nwe embed the lua engine \ngo-lua\n so that it's \npossible to create a custom op if it is not provided. For example if the users wants to\n\n\n\"lua:function sum(t) local sum = 0; for i=1,#t do sum = sum + t[i] end return sum end\"\n\n\n\nwhere the last value (in this case sum) is returned as the annotation value. It is encouraged\nto instead define lua functions in separate \n.lua\n file and point to it when calling\n\nvcfanno\n using the \n-lua\n flag. So, in an external file, \"some.lua\", instead put:\n\n\nfunction sum(t)\n    local sum = 0\n    for i=1,#t do\n        sum = sum + t[i]\n    end\n    return sum\nend\n\n\n\n\nAnd then the above custom op would be: \"lua:sum(vals)\". (note that there's a sum op provided\nby \nvcfanno\n which will be faster).\n\n\nThe variables \nvals\n, \nchrom\n, \nstart\n, \nstop\n from the current variant will all be available\nin the lua code.\n\n\nSee \nexample/conf.toml\n\nand \nexample/custom.lua\n\nfor more examples.", 
            "title": "Home"
        }, 
        {
            "location": "/#vcfanno", 
            "text": "Mailing List  vcfanno annotates a VCF with any number of  sorted  and tabixed input BED, BAM, and VCF files in parallel.\nIt does this by finding overlaps as it streams over the data and applying\nuser-defined operations on the overlapping annotations.  In order to parallelize, work is broken down as follows. A slice (array) of query intervals is accumulated \nuntil a specified number is reached (usually ~5K-25K) or a gap cutoff is exceeded; at that point, the\nbounds of the region are used to perform a tabix (or any regional) query on the database files. This is\nall done in  irelate .  vcfanno  then iterates over the streams that\nresult from the tabix queries and finds intersections with the query stream. This is a parallel chrom-sweep.\nThis method avoids problems with chromosome order.  For VCF, values are pulled by name from the INFO field.\nFor BED, values are pulled from (1-based) column number.\nFor BAM, depth ( count ), \"mapq\" and \"seq\" are currently supported.  vcfanno  is written in  go  and it supports custom user-scripts written in lua.\nIt can annotate more than 8,000 variants per second with 34 annotations from 9 files on a modest laptop and over 30K variants per second using 12 processes on a server.  We are actively developing  vcfanno  and appreciate feedback and bug reports.", 
            "title": "vcfanno"
        }, 
        {
            "location": "/#usage", 
            "text": "After downloading the  binary for your system  (see section below) usage looks like:    ./vcfanno -lua example/custom.lua example/conf.toml example/query.vcf.gz  Where conf.toml looks like:  [[annotation]]\nfile= ExAC.vcf \nfields = [ AC_AFR ,  AC_AMR ,  AC_EAS ]\nops=[ first ,  first ,  min ]\n\n[[annotation]]\nfile= fitcons.bed \ncolumns = [4, 4]\nnames=[ fitcons_mean ,  lua_sum ]\n# note the 2nd op here is lua that has access to `vals`\nops=[ mean ,  lua:function sum(t) local sum = 0; for i=1,#t do sum = sum + t[i] end return sum / #t end ]\n\n[[annotation]]\nfile= example/ex.bam \nnames=[ ex_bam_depth ]\nfields=[ depth ,  mapq ,  seq ]\nops=[ count ,  mean ,  concat ]  So from  ExAC.vcf  we will pull the fields from the info field and apply the corresponding operation  from the  ops  array. Users can add as many  [[annotation]]  blocks to the\nconf file as desired. Files can be local as above, or available via http/https.  Also see the additional usage section at the bottom for additional details.", 
            "title": "Usage"
        }, 
        {
            "location": "/#example", 
            "text": "the example directory contains the data and conf for a full example. To run, either download\nthe  appropriate binary  for your system\nor build with:  go get\ngo build -o vcfanno  from this directory.\nThen, you can annotate with:  ./vcfanno -p 4 -lua example/custom.lua example/conf.toml example/query.vcf.gz   annotated.vcf  An example INFO field row before annotation (pos 98683):  AB=0.282443;ABP=56.8661;AC=11;AF=0.34375;AN=32;AO=45;CIGAR=1X;TYPE=snp  and after:  AB=0.2824;ABP=56.8661;AC=11;AF=0.3438;AN=32;AO=45;CIGAR=1X;TYPE=snp;AC_AFR=0;AC_AMR=0;AC_EAS=0;fitcons_mean=0.061;lua_sum=0.061", 
            "title": "Example"
        }, 
        {
            "location": "/#operations", 
            "text": "In most cases, we will have a single annotation entry for each entry (variant)\nin the query VCF. However, it is possible that there will be multiple annotations\nfrom a single annotation file--in this case, the op determines how the many values\nare  reduced . Valid operations are:   lua:$lua // see section below for more details  mean  max  min  concat // comma delimited list of output  count  // count the number of overlaps  uniq  first   flag   // presense/absence via vcf flag", 
            "title": "Operations"
        }, 
        {
            "location": "/#postannotation", 
            "text": "One of the most powerful features of  vcfanno  is the embedded scripting language, lua, combined with  postannotation . [[postannotation]]  blocks occur after all the annotations have been applied. They are similar, but in the fields\ncolumn, they request a number of columns from the query file (including the new columns added in annotation). For example\nif we have AC and AN columns indicating the alternate count and the number of chromosomes, respectively, we could create\na new allele frequency column,  AF  with this block:  [[postannotation]]\nfields=[ AC ,  AN ]\nop= lua:AC / AN \nname= AF \ntype= Float   where the type field is one of the types accepted in VCF format, the  name  is the name of the field that is created, the  fields \nindicate the fields (from the INFO) that will be available to the op, and the  op  indicates the action to perform. This can be quite\npowerful. For an extensive example that demonstrates the utility of this type of approach, see docs/examples/clinvar_exac.md .", 
            "title": "PostAnnotation"
        }, 
        {
            "location": "/#binaries", 
            "text": "binary executables are available  here \nfor  linux ,  mac  (darwin), and  windows  for  32  and  64  bit platforms.", 
            "title": "Binaries"
        }, 
        {
            "location": "/#preprocessing", 
            "text": "Annotations will be the most accurate if your query and annotation variants are split (no multiple ALTs) and normalized (left-aligned and trimmed). At some point, this will be done internally, but for now, you can get a split and normalized VCF using  vt \nwith:  vt decompose -s $VCF | vt normalize -r $REF -   $NORM_VCF  vcfanno  will check all alternates that are present in both the query and the annotations but the decomposition (splitting alts) will allow for better normalization.", 
            "title": "Preprocessing"
        }, 
        {
            "location": "/#development", 
            "text": "This, and the associated go libraries ( vcfgo , irelate ,  xopen , goluaez  are under active development.", 
            "title": "Development"
        }, 
        {
            "location": "/#additional-usage", 
            "text": "", 
            "title": "Additional Usage"
        }, 
        {
            "location": "/#-ends", 
            "text": "For annotating large variants, such as CNVs or structural variants (SVs), it can be useful to\nannotate the  ends  of the variant in addition to the region itself. To do this, specify the  -ends \nflag to  vcfanno . e.g.:  vcfanno -ends example/conf.toml example/query.vcf.gz  In this case, the names field in the  conf  file contains, \"fitcons_mean\". The output will contain fitcons\\_mean  as before along with  left\\_fitcons\\_mean  and  right\\_fitcons\\_mean  for any variants\nthat are longer than 1 base. The  left  end will be for the single-base at the lowest base of the variant\nand the  right  end will be for the single base at the higher numbered base of the variant.", 
            "title": "-ends"
        }, 
        {
            "location": "/#-permissive-overlap", 
            "text": "By default, when annotating with a variant, in addition to the overlap requirement, the variants must share\nthe same position, the same reference allele and at least one alternate allele (this is only used for\nvariants, not for BED/BAM annotations). If this flag is specified, only overlap testing is used and shared\nREF/ALT are not required.", 
            "title": "-permissive-overlap"
        }, 
        {
            "location": "/#-p", 
            "text": "Set to the number of processes that  vcfanno  can use during annotation.  vcfanno  parallelizes well\nup to 15 or so cores.", 
            "title": "-p"
        }, 
        {
            "location": "/#-lua", 
            "text": "custom in ops (lua). For use when the built-in  ops  don't supply the needed reduction.  we embed the lua engine  go-lua  so that it's \npossible to create a custom op if it is not provided. For example if the users wants to  \"lua:function sum(t) local sum = 0; for i=1,#t do sum = sum + t[i] end return sum end\"  where the last value (in this case sum) is returned as the annotation value. It is encouraged\nto instead define lua functions in separate  .lua  file and point to it when calling vcfanno  using the  -lua  flag. So, in an external file, \"some.lua\", instead put:  function sum(t)\n    local sum = 0\n    for i=1,#t do\n        sum = sum + t[i]\n    end\n    return sum\nend  And then the above custom op would be: \"lua:sum(vals)\". (note that there's a sum op provided\nby  vcfanno  which will be faster).  The variables  vals ,  chrom ,  start ,  stop  from the current variant will all be available\nin the lua code.  See  example/conf.toml \nand  example/custom.lua \nfor more examples.", 
            "title": "-lua"
        }, 
        {
            "location": "/performance_tips/", 
            "text": "Performance Tips\n\n\nFollowing the \ngolang\n philosophy, there are few knobs\nto turn for tweaking performance.\n\n\nProcesses\n\n\nThe simplest performance tweak is to use \n-p PROCS\n to specify the number\nof processes to use when running \nvcfanno\n. It scales well to ~15 processes.\n\n\nGarbage Collection\n\n\nOn machines with even modest amounts of memory, it can be good to allow\n\ngo\n to use more memory for the benefit of spending less time in garbage\ncollection. Users can do this by preceding their \nvcfanno\n command with\n\nGOGC=1000\n. Where higher values allow \ngo\n to use more memory and the\ndefault value is 100. For example:\n\n\nGOGC=2000 vcfanno -p 12 a.conf a.vcf\n\n\n\n\nMax Gap Size\n\n\nThe parallel chrom-sweep algorithm has a gap size parameter that determines\nwhen a chunk of records from the the query file is sent to be annotated. If\na gap of a certain\nsize is encountered, a new chunk is sent off. Given a (number of) dense\nannotation file(s), it might be good to reduce the gap size so that \nvcfanno\n\nwill need to parse fewer unneeded records. However, given sparse annotation\nsets, it is best to have this value be large so that each annotation worker\ngets enough work to keep it busy.\n\n\nThe default gap size is \n20000\n bases. Users can alter this using the\nenvironment variable \nIRELATE_MAX_GAP\n e.g.:\n\n\nIRELATE_MAX_GAP=5000 vcfanno -p 12 a.conf a.vcf", 
            "title": "Performance"
        }, 
        {
            "location": "/performance_tips/#performance-tips", 
            "text": "Following the  golang  philosophy, there are few knobs\nto turn for tweaking performance.", 
            "title": "Performance Tips"
        }, 
        {
            "location": "/performance_tips/#processes", 
            "text": "The simplest performance tweak is to use  -p PROCS  to specify the number\nof processes to use when running  vcfanno . It scales well to ~15 processes.", 
            "title": "Processes"
        }, 
        {
            "location": "/performance_tips/#garbage-collection", 
            "text": "On machines with even modest amounts of memory, it can be good to allow go  to use more memory for the benefit of spending less time in garbage\ncollection. Users can do this by preceding their  vcfanno  command with GOGC=1000 . Where higher values allow  go  to use more memory and the\ndefault value is 100. For example:  GOGC=2000 vcfanno -p 12 a.conf a.vcf", 
            "title": "Garbage Collection"
        }, 
        {
            "location": "/performance_tips/#max-gap-size", 
            "text": "The parallel chrom-sweep algorithm has a gap size parameter that determines\nwhen a chunk of records from the the query file is sent to be annotated. If\na gap of a certain\nsize is encountered, a new chunk is sent off. Given a (number of) dense\nannotation file(s), it might be good to reduce the gap size so that  vcfanno \nwill need to parse fewer unneeded records. However, given sparse annotation\nsets, it is best to have this value be large so that each annotation worker\ngets enough work to keep it busy.  The default gap size is  20000  bases. Users can alter this using the\nenvironment variable  IRELATE_MAX_GAP  e.g.:  IRELATE_MAX_GAP=5000 vcfanno -p 12 a.conf a.vcf", 
            "title": "Max Gap Size"
        }, 
        {
            "location": "/CHANGES/", 
            "text": "v0.0.10 (dev)\n\n\n\n\nallow using postannotation even if not all requested fields were found for a given variant.\n\n\n\n\nv0.0.9\n\n\n\n\nrestore ability to take query file from STDIN (no tabix required).\n\n\nfix memory leak. memory use now scales with number of procs (-p).\n\n\nadded new op 'self' which should be used for most cases when matching on ref and alt as it\n  determines the type from the annotation header and uses that to update the annotated header\n  with the correct type.\n\n\nnew \ndocumentation site\n\n\n[[postannotation]] allows modifying stuff in the query VCF after annotation (or instead).\n  See examples on the documentation site.\n\n\nconvert scripting engine to lua from javascript\n\n\nadd CADD conversion script and example\n\n\n\n\nv0.0.8\n\n\n\n\nparallel chrom-sweep (removes problems with chromosome sort order).\n\n\nas a result, files are required to be tabix'ed.\n\n\nthe chromosome sort order is no longer important.\n\n\nfix bug in SV support of CIPOS, CIENDS\n\n\nhuge speed improvement (can annotate ~30K variants/second with 10 cpus).\n\n\nremove server and cadd support (will return soon).\n\n\nfix bug where header is not updated.\n\n\nrespect strict when -ends is used.\n\n\n\n\nv0.0.7\n\n\n\n\nbetter support for flags. e.g. can specify a flag from js by ending the function name with _flag\n\n\n[irelate] error if intervals are out of order within a file.\n\n\n-base-path argument replaces basepath in .toml file\n\n\n[vcfgo] report all headers in original file.\n\n\nintegrated server to host annotations\n\n\n-ends argument will now use CIPOS and CIEND to annotate the left and right interval of an SV. If CIPOS\n   and CIEND are undefined for a given interval, the ends will not be annotated.\n\n\nfor MNPs, cadd score is reported as a list of max values (of the 3 possible changes) for each reference base\n  covered by the event.\n\n\nfix bug in CADD annotation and provide CADD v1.3 download\n\n\n~25-30% speed improvement. from a modest laptop:  \nannotated 10195872 variants in 28.97 minutes (351984.0 / minute)\n\n\n\n\nv0.0.6\n\n\n\n\nsupport for CADD\n\n\nconcat defaults to | separator\n\n\nspeed improvements (vcfgo info field)\n\n\nnatural sort is default. use -lexographical to\n\n\n\n\nv0.0.5\n\n\n\n\nallow natural sort (1, 2, ... 9, 10, 11 instead of 1, 10, 11 ..., 19, 2, 20) via flag\n\n\nvcfgo: handle lines longer than 65KB \nmajor\n\n\nvcfgo: fix error reporting\n\n\nirelate: report warning when chroms out of order\n\n\n\n\nv0.0.4\n\n\n\n\nperformance improvements for Javascript ops with pre-compilation.\n\n\nbam: annotate with \nmapq\n and \nseq\n for mapping-quality and sequence respectively.\n\n\napi now returns a channel on which to recieve annotated Relatables\n\n\nvcfgo: fix printing of INFO fields with multiple values (thanks to Liron for reporting).\n\n\nvcfgo: fix writing of ##SAMPLE and ##PEDIGREE headers. (thanks to Liron)\n\n\n\n\nv0.0.3\n\n\n\n\ncustom ops with javascript.\n\n\nproper support for \n, \n\n\noption to annotate BED files.\n\n\nvcfanno has an \napi\n so it can be\n  used from other progs.", 
            "title": "Changes"
        }, 
        {
            "location": "/CHANGES/#v0010-dev", 
            "text": "allow using postannotation even if not all requested fields were found for a given variant.", 
            "title": "v0.0.10 (dev)"
        }, 
        {
            "location": "/CHANGES/#v009", 
            "text": "restore ability to take query file from STDIN (no tabix required).  fix memory leak. memory use now scales with number of procs (-p).  added new op 'self' which should be used for most cases when matching on ref and alt as it\n  determines the type from the annotation header and uses that to update the annotated header\n  with the correct type.  new  documentation site  [[postannotation]] allows modifying stuff in the query VCF after annotation (or instead).\n  See examples on the documentation site.  convert scripting engine to lua from javascript  add CADD conversion script and example", 
            "title": "v0.0.9"
        }, 
        {
            "location": "/CHANGES/#v008", 
            "text": "parallel chrom-sweep (removes problems with chromosome sort order).  as a result, files are required to be tabix'ed.  the chromosome sort order is no longer important.  fix bug in SV support of CIPOS, CIENDS  huge speed improvement (can annotate ~30K variants/second with 10 cpus).  remove server and cadd support (will return soon).  fix bug where header is not updated.  respect strict when -ends is used.", 
            "title": "v0.0.8"
        }, 
        {
            "location": "/CHANGES/#v007", 
            "text": "better support for flags. e.g. can specify a flag from js by ending the function name with _flag  [irelate] error if intervals are out of order within a file.  -base-path argument replaces basepath in .toml file  [vcfgo] report all headers in original file.  integrated server to host annotations  -ends argument will now use CIPOS and CIEND to annotate the left and right interval of an SV. If CIPOS\n   and CIEND are undefined for a given interval, the ends will not be annotated.  for MNPs, cadd score is reported as a list of max values (of the 3 possible changes) for each reference base\n  covered by the event.  fix bug in CADD annotation and provide CADD v1.3 download  ~25-30% speed improvement. from a modest laptop:   annotated 10195872 variants in 28.97 minutes (351984.0 / minute)", 
            "title": "v0.0.7"
        }, 
        {
            "location": "/CHANGES/#v006", 
            "text": "support for CADD  concat defaults to | separator  speed improvements (vcfgo info field)  natural sort is default. use -lexographical to", 
            "title": "v0.0.6"
        }, 
        {
            "location": "/CHANGES/#v005", 
            "text": "allow natural sort (1, 2, ... 9, 10, 11 instead of 1, 10, 11 ..., 19, 2, 20) via flag  vcfgo: handle lines longer than 65KB  major  vcfgo: fix error reporting  irelate: report warning when chroms out of order", 
            "title": "v0.0.5"
        }, 
        {
            "location": "/CHANGES/#v004", 
            "text": "performance improvements for Javascript ops with pre-compilation.  bam: annotate with  mapq  and  seq  for mapping-quality and sequence respectively.  api now returns a channel on which to recieve annotated Relatables  vcfgo: fix printing of INFO fields with multiple values (thanks to Liron for reporting).  vcfgo: fix writing of ##SAMPLE and ##PEDIGREE headers. (thanks to Liron)", 
            "title": "v0.0.4"
        }, 
        {
            "location": "/CHANGES/#v003", 
            "text": "custom ops with javascript.  proper support for  ,   option to annotate BED files.  vcfanno has an  api  so it can be\n  used from other progs.", 
            "title": "v0.0.3"
        }, 
        {
            "location": "/examples/clinvar_exac/", 
            "text": "Annotate Clinvar With ExAC\n\n\nThe \nExAC paper\n notes that\nsome of the variants in \nClinVar\n that \nare classified as pathogenic (or likely pathogenic) are actually in high enough (\n1%)\nallele frequency in ExAC to indicate that it is unlikely that these are really pathogenic.\n\n\nHere, we will use \nvcfanno\n to annotate the clinvar VCF with the allele frequencies\nfor ExAC so that we can find variants that are indicated as pathogenic \nand\n rare in ExAC.\n\n\nThe ExAC reports the alternate counts and the total number of chromosomes (\nAN*\n) and the\nalternate allele counts (\nAC*\n) so, to we will annotate with those and then use \npostannotation\n\nin \nvcfanno\n to get the \nAF\n as \nAC/AN\n. We will use\nan already \ndecomposed and normalized\n version of\nExAC (but vcfanno will match on any of the alternate alleles if multiple are present for a given\nvariant). The \n[[annotation]]\n section in the config file will look like this:\n\n\nExAC Config\n\n\n[[annotation]]\nfile=\nExAC.r0.3.sites.vep.tidy.vcf.gz\n\nfields = [\nAC_Adj\n, \nAN_Adj\n, \nAC_AFR\n, \nAN_AFR\n, \nAC_AMR\n, \nAN_AMR\n, \nAC_EAS\n, \nAN_EAS\n, \nAC_FIN\n, \nAN_FIN\n, \nAC_NFE\n, \nAN_NFE\n, \nAC_OTH\n, \nAN_OTH\n, \nAC_SAS\n, \nAN_SAS\n]\nnames = [\nac_exac_all\n, \nan_exac_all\n, \nac_exac_afr\n, \nan_exac_afr\n, \nac_exac_amr\n, \nan_exac_amr\n, \nac_exac_eas\n, \nan_exac_eas\n, \nac_exac_fin\n, \nan_exac_fin\n, \nac_exac_nfe\n, \nan_exac_nfe\n, \nac_exac_oth\n, \nan_exac_oth\n, \nac_exac_sas\n, \nan_exac_sas\n]\nops=[\nself\n, \nself\n, \nself\n, \nself\n, \nself\n, \nself\n, \nself\n, \nself\n, \nself\n, \nself\n, \nself\n, \nself\n, \nself\n, \nself\n, \nself\n, \nself\n]\n\n\n\n\nNote that we can have as many of these sections as we want with vcfanno, but here we are only\ninterested in annotating clinvar with the single ExAC file. The \nfields\n section indicates which\nfields to pull from the \nExAC\n VCF. The \nnames\n section indicates how those fields will be named\nas they are added to the clinvar VCF. Since we intend to match on REF and ALT, there will only\nbe 1 match so the \nop\n is just \"self\" for all fields.\n\n\nBecause we want to know the allele frequency, we will need to divide \nAC\n by \nAN\n. This is done in a \n[[postannotation]]\n\nsection that looks like this:\n\n\nPostAnnotation\n\n\n[[postannotation]]\nfields=[\nac_exac_all\n, \nan_exac_all\n]\nname=\naf_exac_all\n\nop=\ndiv2\n\ntype=\nFloat\n\n\n\n\n\nWe need one of these section for each population, which is onerous, but simple enough to generate with\na small script. Note that the op \ndiv\n is provided by \nvcfanno\n, but we could have written this as a\ncustom op in lua as:\n\n\nfunction div(a, b)\n    if(a == 0){ return 0.0; }\n    return string.format(\n%.9f\n, a / b)\n}\n\n\n\n\nand then use:\n\n\nop=\nlua:div(ac_exac_all, an_exac_all)\n\n\n\n\n\nin the \n[[postannotation]]\n.\n\n\nThese \npostannotation\n sections are executed in the order they are specified so we can specify a final section that\ntakes the maximum of all of the allele frequencies. This is informative as a truly pathogenic variant should have a\nlow allele frequency in all populations. Here is the section to take the maximum AF of all the populations which\nwe've already calculated:\n\n\n[[postannotation]]\nfields=[\naf_exac_all\n, \naf_exac_afr\n, \naf_exac_amr\n, \naf_exac_eas\n, \naf_exac_nfe\n, \naf_exac_oth\n, \naf_exac_sas\n]\nop=\nmax\n\nname=\nmax_aaf_all\n\ntype=\nFloat\n\n\n\n\n\nFlag Common Pathogenic\n\n\nFinally, we can flag variants that have a \nmax_aaf_all\n above some cutoff and are labelled as pathogenic.\n\n\n[[postannotation]]\nfields=[\nclinvar_sig\n, \nmax_aaf_all\n]\nop=\nlua:check_clinvar_aaf(clinvar_sig, max_aaf_all, 0.005)\n\nname=\ncommon_pathogenic\n\ntype=\nFlag\n\n\n\n\n\nNote that we use 0.005 as the allele frequency cutoff. For any variant that was not present in ExAC, the \nmax_aaf_all\n field\nwill be absent from the INFO field and so this will not be called.\n\n\nIf we've saved this in a file called \nexac-af.conf\n then the vcfanno command looks like:\n\n\nvcfanno -lua clinvar_exac.lua -p 4 -base-path $EXAC_DIR clinvar_exac.conf $CLINVAR_VCF \n $CLINVAR_ANNOTATED_VCF\n\n\n\n\nThis command finishes in about 2 minutes on a good laptop with a core i7 processor.\n\n\nAn example INFO field from the clinvar file after annotation looks like this:\n\n\nRS=17855739;RSPOS=5831840;RV;dbSNPBuildID=123;SSR=0;SAO=1;VP=0x050060000a05150136110100;GENEINFO=FUT6:2528;WGT=1;VC=SNV;PM;NSM;REF;ASP;VLD;G5;GNO;KGPhase1;KGPhase3;LSD;OM;CLNALLE=1;CLNHGVS=NC_000019.9:g.5831840C\nT;CLNSRC=OMIM_Allelic_Variant;CLNORIGIN=1;CLNSRCID=136836.0001;CLNSIG=5;CLNDSDB=MedGen:OMIM;CLNDSDBID=C3151219:613852;CLNDBN=Fucosyltransferase_6_deficiency;CLNREVSTAT=single;CLNACC=RCV000017626.26;CAF=0.8393,0.1607;COMMON=1;ac_exac_all=10114;an_exac_all=121354;ac_exac_afr=3093;an_exac_afr=10402;ac_exac_amr=449;an_exac_amr=11572;ac_exac_eas=867;an_exac_eas=8638;ac_exac_fin=210;an_exac_fin=6612;ac_exac_nfe=2836;an_exac_nfe=66712;ac_exac_oth=62;an_exac_oth=906;ac_exac_sas=2597;an_exac_sas=16512;af_exac_all=0.0833;af_exac_afr=0.2973;af_exac_amr=0.0388;af_exac_eas=0.1004;af_exac_nfe=0.0425;af_exac_oth=0.0684;af_exac_sas=0.1573;max_aaf_all=0.2973;clinvar_sig=pathogenic;common_pathogenic\n\n\n\n\n(NOTE that clinvar has applied the \nCOMMON=1\n tag here indicating a high AF in 1kg.)\n\n\nWith our ExAC fields appearing at the end:\n\n\nac_exac_all=10114;an_exac_all=121354;ac_exac_afr=3093;an_exac_afr=10402;ac_exac_amr=449;an_exac_amr=11572;ac_exac_eas=867;an_exac_eas=8638;ac_exac_fin=210;an_exac_fin=6612;ac_exac_nfe=2836;an_exac_nfe=66712;ac_exac_oth=62;an_exac_oth=906;ac_exac_sas=2597;an_exac_sas=16512;af_exac_all=0.0833;af_exac_afr=0.2973;af_exac_amr=0.0388;af_exac_eas=0.1004;af_exac_nfe=0.0425;af_exac_oth=0.0684;af_exac_sas=0.1573;max_aaf_all=0.2973;clinvar_sig=pathogenic;common_pathogenic\n\n\n\n\nSo this variant was classified as pathogenic, but has a \nmax_aaf_all\n of 0.2973 and so it received the 'common_pathogenic' flag as did 566 other clinvar variants.\n\n\nWhile the config file used to generate this final dataset was fairly involved, each step is very simple and it shows the power in vcfanno.\nHowever, note that for most analyses, it will be sufficient to specify a config file that pulls the fields of\ninterest.\n\n\nSupporting Files\n\n\nThe full config and lua files used to run this analysis are available \nhere\n.", 
            "title": "ClinvarExac"
        }, 
        {
            "location": "/examples/clinvar_exac/#annotate-clinvar-with-exac", 
            "text": "The  ExAC paper  notes that\nsome of the variants in  ClinVar  that \nare classified as pathogenic (or likely pathogenic) are actually in high enough ( 1%)\nallele frequency in ExAC to indicate that it is unlikely that these are really pathogenic.  Here, we will use  vcfanno  to annotate the clinvar VCF with the allele frequencies\nfor ExAC so that we can find variants that are indicated as pathogenic  and  rare in ExAC.  The ExAC reports the alternate counts and the total number of chromosomes ( AN* ) and the\nalternate allele counts ( AC* ) so, to we will annotate with those and then use  postannotation \nin  vcfanno  to get the  AF  as  AC/AN . We will use\nan already  decomposed and normalized  version of\nExAC (but vcfanno will match on any of the alternate alleles if multiple are present for a given\nvariant). The  [[annotation]]  section in the config file will look like this:", 
            "title": "Annotate Clinvar With ExAC"
        }, 
        {
            "location": "/examples/clinvar_exac/#exac-config", 
            "text": "[[annotation]]\nfile= ExAC.r0.3.sites.vep.tidy.vcf.gz \nfields = [ AC_Adj ,  AN_Adj ,  AC_AFR ,  AN_AFR ,  AC_AMR ,  AN_AMR ,  AC_EAS ,  AN_EAS ,  AC_FIN ,  AN_FIN ,  AC_NFE ,  AN_NFE ,  AC_OTH ,  AN_OTH ,  AC_SAS ,  AN_SAS ]\nnames = [ ac_exac_all ,  an_exac_all ,  ac_exac_afr ,  an_exac_afr ,  ac_exac_amr ,  an_exac_amr ,  ac_exac_eas ,  an_exac_eas ,  ac_exac_fin ,  an_exac_fin ,  ac_exac_nfe ,  an_exac_nfe ,  ac_exac_oth ,  an_exac_oth ,  ac_exac_sas ,  an_exac_sas ]\nops=[ self ,  self ,  self ,  self ,  self ,  self ,  self ,  self ,  self ,  self ,  self ,  self ,  self ,  self ,  self ,  self ]  Note that we can have as many of these sections as we want with vcfanno, but here we are only\ninterested in annotating clinvar with the single ExAC file. The  fields  section indicates which\nfields to pull from the  ExAC  VCF. The  names  section indicates how those fields will be named\nas they are added to the clinvar VCF. Since we intend to match on REF and ALT, there will only\nbe 1 match so the  op  is just \"self\" for all fields.  Because we want to know the allele frequency, we will need to divide  AC  by  AN . This is done in a  [[postannotation]] \nsection that looks like this:", 
            "title": "ExAC Config"
        }, 
        {
            "location": "/examples/clinvar_exac/#postannotation", 
            "text": "[[postannotation]]\nfields=[ ac_exac_all ,  an_exac_all ]\nname= af_exac_all \nop= div2 \ntype= Float   We need one of these section for each population, which is onerous, but simple enough to generate with\na small script. Note that the op  div  is provided by  vcfanno , but we could have written this as a\ncustom op in lua as:  function div(a, b)\n    if(a == 0){ return 0.0; }\n    return string.format( %.9f , a / b)\n}  and then use:  op= lua:div(ac_exac_all, an_exac_all)   in the  [[postannotation]] .  These  postannotation  sections are executed in the order they are specified so we can specify a final section that\ntakes the maximum of all of the allele frequencies. This is informative as a truly pathogenic variant should have a\nlow allele frequency in all populations. Here is the section to take the maximum AF of all the populations which\nwe've already calculated:  [[postannotation]]\nfields=[ af_exac_all ,  af_exac_afr ,  af_exac_amr ,  af_exac_eas ,  af_exac_nfe ,  af_exac_oth ,  af_exac_sas ]\nop= max \nname= max_aaf_all \ntype= Float", 
            "title": "PostAnnotation"
        }, 
        {
            "location": "/examples/clinvar_exac/#flag-common-pathogenic", 
            "text": "Finally, we can flag variants that have a  max_aaf_all  above some cutoff and are labelled as pathogenic.  [[postannotation]]\nfields=[ clinvar_sig ,  max_aaf_all ]\nop= lua:check_clinvar_aaf(clinvar_sig, max_aaf_all, 0.005) \nname= common_pathogenic \ntype= Flag   Note that we use 0.005 as the allele frequency cutoff. For any variant that was not present in ExAC, the  max_aaf_all  field\nwill be absent from the INFO field and so this will not be called.  If we've saved this in a file called  exac-af.conf  then the vcfanno command looks like:  vcfanno -lua clinvar_exac.lua -p 4 -base-path $EXAC_DIR clinvar_exac.conf $CLINVAR_VCF   $CLINVAR_ANNOTATED_VCF  This command finishes in about 2 minutes on a good laptop with a core i7 processor.  An example INFO field from the clinvar file after annotation looks like this:  RS=17855739;RSPOS=5831840;RV;dbSNPBuildID=123;SSR=0;SAO=1;VP=0x050060000a05150136110100;GENEINFO=FUT6:2528;WGT=1;VC=SNV;PM;NSM;REF;ASP;VLD;G5;GNO;KGPhase1;KGPhase3;LSD;OM;CLNALLE=1;CLNHGVS=NC_000019.9:g.5831840C T;CLNSRC=OMIM_Allelic_Variant;CLNORIGIN=1;CLNSRCID=136836.0001;CLNSIG=5;CLNDSDB=MedGen:OMIM;CLNDSDBID=C3151219:613852;CLNDBN=Fucosyltransferase_6_deficiency;CLNREVSTAT=single;CLNACC=RCV000017626.26;CAF=0.8393,0.1607;COMMON=1;ac_exac_all=10114;an_exac_all=121354;ac_exac_afr=3093;an_exac_afr=10402;ac_exac_amr=449;an_exac_amr=11572;ac_exac_eas=867;an_exac_eas=8638;ac_exac_fin=210;an_exac_fin=6612;ac_exac_nfe=2836;an_exac_nfe=66712;ac_exac_oth=62;an_exac_oth=906;ac_exac_sas=2597;an_exac_sas=16512;af_exac_all=0.0833;af_exac_afr=0.2973;af_exac_amr=0.0388;af_exac_eas=0.1004;af_exac_nfe=0.0425;af_exac_oth=0.0684;af_exac_sas=0.1573;max_aaf_all=0.2973;clinvar_sig=pathogenic;common_pathogenic  (NOTE that clinvar has applied the  COMMON=1  tag here indicating a high AF in 1kg.)  With our ExAC fields appearing at the end:  ac_exac_all=10114;an_exac_all=121354;ac_exac_afr=3093;an_exac_afr=10402;ac_exac_amr=449;an_exac_amr=11572;ac_exac_eas=867;an_exac_eas=8638;ac_exac_fin=210;an_exac_fin=6612;ac_exac_nfe=2836;an_exac_nfe=66712;ac_exac_oth=62;an_exac_oth=906;ac_exac_sas=2597;an_exac_sas=16512;af_exac_all=0.0833;af_exac_afr=0.2973;af_exac_amr=0.0388;af_exac_eas=0.1004;af_exac_nfe=0.0425;af_exac_oth=0.0684;af_exac_sas=0.1573;max_aaf_all=0.2973;clinvar_sig=pathogenic;common_pathogenic  So this variant was classified as pathogenic, but has a  max_aaf_all  of 0.2973 and so it received the 'common_pathogenic' flag as did 566 other clinvar variants.  While the config file used to generate this final dataset was fairly involved, each step is very simple and it shows the power in vcfanno.\nHowever, note that for most analyses, it will be sufficient to specify a config file that pulls the fields of\ninterest.", 
            "title": "Flag Common Pathogenic"
        }, 
        {
            "location": "/examples/clinvar_exac/#supporting-files", 
            "text": "The full config and lua files used to run this analysis are available  here .", 
            "title": "Supporting Files"
        }, 
        {
            "location": "/examples/cadd/", 
            "text": "Annotate with CADD\n\n\nThis documents how to use \nvcfanno\n to annotate a VCF with CADD scores.\n\n\n\"CADD is a tool for scoring the deleteriousness of single nucleotide variants as well as insertion/deletions variants in the human genome.\"\n\nUsers of CADD should refer to the \nweb page\n for citation and use requirements.\n\n\nSetup\n\n\nIn order to use CADD with \nvcfanno\n, we must convert the tsv format provided by CADD to VCF. We can do this with \na\npython script\n. After downloading the \nAll possible SNVs of GRCh37/hg19\n filre from the \nCADD website\n we can run as:\n\n\npython cadd2vcf.py whole_genome_SNVs.tsv.gz | bgzip -c \n cadd_v1.3.vcf.gz\ntabix cadd_v1.3.vcf.gz\n\n\n\n\nThis will create a 50GB vcf.gz from the 80GB tsv.gz. \nThe entirety of the INFO field for a given record will look like: \"raw=0.34;phred=6.05\"\n\n\nConfig\n\n\nFrom here, we can specify a conf file:\n\n\n[[annotation]]\nfile=\ncadd_v1.3.vcf.gz\n\nnames=[\ncadd_phred\n, \ncadd_raw\n]\nops=[\nmean\n, \nmean\n]\nfields=[\nphred\n, \nraw\n]\n\n\n\n\nAnnotation\n\n\nAnd we can run \nvcfanno\n as:\n\n\nvcfanno -p 12 cadd.conf query.vcf \n query.anno.vcf\n\n\n\n\nAs an extreme case, we can run this on the ExAC VCF:\n\n\nvcfanno -p 18 cadd.conf ExAC.r0.3.sites.vep.tidy.vcf.gz | bgzip -c \n /tmp/exac-cadd.vcf.gz\n\n\n\n\nThis takes about 88 minutes on a good server. This time will improve in future versions but it\nis due to the large number of lines that must be parsed from the CADD VCF, even with the algorithm\nthat allows it to avoid parsing annotation intervals that fall in large gaps in the query. By\ncomparison, \nbedtools intersect -sorted\n takes 92 minutes for this same overlap.\n\n\nNote\n\n\nThis will only work for single-nucleotide variants since the default for VCF is to match on REF and ALT.", 
            "title": "CADD"
        }, 
        {
            "location": "/examples/cadd/#annotate-with-cadd", 
            "text": "This documents how to use  vcfanno  to annotate a VCF with CADD scores.  \"CADD is a tool for scoring the deleteriousness of single nucleotide variants as well as insertion/deletions variants in the human genome.\" \nUsers of CADD should refer to the  web page  for citation and use requirements.", 
            "title": "Annotate with CADD"
        }, 
        {
            "location": "/examples/cadd/#setup", 
            "text": "In order to use CADD with  vcfanno , we must convert the tsv format provided by CADD to VCF. We can do this with  a\npython script . After downloading the  All possible SNVs of GRCh37/hg19  filre from the  CADD website  we can run as:  python cadd2vcf.py whole_genome_SNVs.tsv.gz | bgzip -c   cadd_v1.3.vcf.gz\ntabix cadd_v1.3.vcf.gz  This will create a 50GB vcf.gz from the 80GB tsv.gz. \nThe entirety of the INFO field for a given record will look like: \"raw=0.34;phred=6.05\"", 
            "title": "Setup"
        }, 
        {
            "location": "/examples/cadd/#config", 
            "text": "From here, we can specify a conf file:  [[annotation]]\nfile= cadd_v1.3.vcf.gz \nnames=[ cadd_phred ,  cadd_raw ]\nops=[ mean ,  mean ]\nfields=[ phred ,  raw ]", 
            "title": "Config"
        }, 
        {
            "location": "/examples/cadd/#annotation", 
            "text": "And we can run  vcfanno  as:  vcfanno -p 12 cadd.conf query.vcf   query.anno.vcf  As an extreme case, we can run this on the ExAC VCF:  vcfanno -p 18 cadd.conf ExAC.r0.3.sites.vep.tidy.vcf.gz | bgzip -c   /tmp/exac-cadd.vcf.gz  This takes about 88 minutes on a good server. This time will improve in future versions but it\nis due to the large number of lines that must be parsed from the CADD VCF, even with the algorithm\nthat allows it to avoid parsing annotation intervals that fall in large gaps in the query. By\ncomparison,  bedtools intersect -sorted  takes 92 minutes for this same overlap.", 
            "title": "Annotation"
        }, 
        {
            "location": "/examples/cadd/#note", 
            "text": "This will only work for single-nucleotide variants since the default for VCF is to match on REF and ALT.", 
            "title": "Note"
        }, 
        {
            "location": "/examples/exac_combine/exac_combine/", 
            "text": "Combine ExAC with non-psych and nonTCGA\n\n\nExAC originally released a VCF that contained the aggregate data for all samples.\nIt has INFO fields for \nAFR\n, \nAMR\n, \nEAS\n, \nFIN\n, \nNFE\n, \nOTH\n, and \nSAS\n populations\nalong with the combined \nAdj\n count.\nRecently, 2 additional VCF's that contain only non pyschiatric and only non TCGA samples\nhave been released.\n\n\nHere, we will use \nvcfanno\n to decorate the original VCF with the alternate counts, \nchromosome counts, number of hets, number of hom alts, and allele frequencies of all populations\nfrom each of the 2 additional VCFs. Since the original VCF contains only allele counts, we will\nalso use \nvcfanno\n to calculate the allele frequency for the original, full population. Finally,\nwe'll calculate the maximum allele frequency from all populations \nas that is very useful for\nfiltering\n.\n\n\nCreating a \nconf\n file can be cumbersome, but in this case, it's simple, if repetitive. As such\nwe write a \nscript\n to create a block like this:\n\n\n[[annotation]]\nfile=\nExAC.r0.3.nonpsych.sites.tidy.vcf.gz\n\nfields=[\nAC_AFR\n,\nAN_AFR\n,\nHom_AFR\n,\nHet_AFR\n,\nAC_AMR\n,\nAN_AMR\n,\nHom_AMR\n,\nHet_AMR\n,\nAC_Adj\n,\nAN_Adj\n,\nAC_EAS\n,\nAN_EAS\n,\nHom_EAS\n,\nHet_EAS\n,\nAC_FIN\n,\nAN_FIN\n,\nHom_FIN\n,\nHet_FIN\n,\nAC_NFE\n,\nAN_NFE\n,\nHom_NFE\n,\nHet_NFE\n,\nAC_OTH\n,\nAN_OTH\n,\nHom_OTH\n,\nHet_OTH\n,\nAC_SAS\n,\nAN_SAS\n,\nHom_SAS\n,\nHet_SAS\n]\nops=[\nself\n,\nself\n,\nself\n,\nself\n,\nself\n,\nself\n,\nself\n,\nself\n,\nself\n,\nself\n,\nself\n,\nself\n,\nself\n,\nself\n,\nself\n,\nself\n,\nself\n,\nself\n,\nself\n,\nself\n,\nself\n,\nself\n,\nself\n,\nself\n,\nself\n,\nself\n,\nself\n,\nself\n,\nself\n,\nself\n]\nnames=[\nnonpsych_AC_AFR\n,\nnonpsych_AN_AFR\n,\nnonpsych_Hom_AFR\n,\nnonpsych_Het_AFR\n,\nnonpsych_AC_AMR\n,\nnonpsych_AN_AMR\n,\nnonpsych_Hom_AMR\n,\nnonpsych_Het_AMR\n,\nnonpsych_AC_Adj\n,\nnonpsych_AN_Adj\n,\nnonpsych_AC_EAS\n,\nnonpsych_AN_EAS\n,\nnonpsych_Hom_EAS\n,\nnonpsych_Het_EAS\n,\nnonpsych_AC_FIN\n,\nnonpsych_AN_FIN\n,\nnonpsych_Hom_FIN\n,\nnonpsych_Het_FIN\n,\nnonpsych_AC_NFE\n,\nnonpsych_AN_NFE\n,\nnonpsych_Hom_NFE\n,\nnonpsych_Het_NFE\n,\nnonpsych_AC_OTH\n,\nnonpsych_AN_OTH\n,\nnonpsych_Hom_OTH\n,\nnonpsych_Het_OTH\n,\nnonpsych_AC_SAS\n,\nnonpsych_AN_SAS\n,\nnonpsych_Hom_SAS\n,\nnonpsych_Het_SAS\n]\n\n\n\n\nAnd a similar one for \nnonTCGA\n. \nIn \nvcfanno\n, \n[[postannotation]]\n sections occur after any \n[[annotation]]\n sections and operate on the fields that are then in the \nINFO of the query. Given multiple \n[[postannotation]]\n sections, they will operate in the order that they appear in the file so later\nsections have access to fields created by earlier sections.\n\n\nWith that in mind, we create a section like this:\n\n\n[[postannotation]]\nfields=[\nnonpsych_AC_NFE\n, \nnonpsych_AN_NFE\n]\nname=\nnonpsych_af_NFE\n\nop=\ndiv2\n\ntype=\nFloat\n\n\n\n\n\nfor each population and for the original superset as well as for nonpsych, nonTCGA. The script to create all this automatically is \nhere\n\n\nThen we have a final section that calculates the maximum allele frequency among all populations:\n\n\n[[postannotation]]\nfields=[\naf_AFR\n, \naf_AMR\n, \naf_EAS\n, \naf_FIN\n, \naf_NFE\n, \naf_OTH\n, \naf_SAS\n, \nnonTCGA_af_AFR\n, \nnonTCGA_af_AMR\n, \nnonTCGA_af_EAS\n, \nnonTCGA_af_FIN\n, \nnonTCGA_af_NFE\n, \nnonTCGA_af_OTH\n, \nnonTCGA_af_SAS\n, \nnonpysch_af_AFR\n, \nnonpysch_af_AMR\n, \nnonpysch_af_EAS\n, \nnonpysch_af_FIN\n, \nnonpysch_af_NFE\n, \nnonpysch_af_OTH\n, \nnonpysch_af_SAS\n]\nop=\nmax\n\nname=\nmax_af_ALL\n\ntype=\nFloat\n\n\n\n\n\nThe entire conf file is \nhere\n\n\nThen, the \nvcfanno\n command is very simple:\n\n\nvcfanno -p 8 exac_combine.conf ExAC.r0.3.sites.vep.tidy.vcf.gz | bgzip -c \n ExAC.r0.3.all.tidy.vcf.gz\n\n\n\n\nThis runs in about 15 minutes (10K variants / second) on good server with fast disk.", 
            "title": "ExAC-Combine"
        }, 
        {
            "location": "/examples/exac_combine/exac_combine/#combine-exac-with-non-psych-and-nontcga", 
            "text": "ExAC originally released a VCF that contained the aggregate data for all samples.\nIt has INFO fields for  AFR ,  AMR ,  EAS ,  FIN ,  NFE ,  OTH , and  SAS  populations\nalong with the combined  Adj  count.\nRecently, 2 additional VCF's that contain only non pyschiatric and only non TCGA samples\nhave been released.  Here, we will use  vcfanno  to decorate the original VCF with the alternate counts, \nchromosome counts, number of hets, number of hom alts, and allele frequencies of all populations\nfrom each of the 2 additional VCFs. Since the original VCF contains only allele counts, we will\nalso use  vcfanno  to calculate the allele frequency for the original, full population. Finally,\nwe'll calculate the maximum allele frequency from all populations  as that is very useful for\nfiltering .  Creating a  conf  file can be cumbersome, but in this case, it's simple, if repetitive. As such\nwe write a  script  to create a block like this:  [[annotation]]\nfile= ExAC.r0.3.nonpsych.sites.tidy.vcf.gz \nfields=[ AC_AFR , AN_AFR , Hom_AFR , Het_AFR , AC_AMR , AN_AMR , Hom_AMR , Het_AMR , AC_Adj , AN_Adj , AC_EAS , AN_EAS , Hom_EAS , Het_EAS , AC_FIN , AN_FIN , Hom_FIN , Het_FIN , AC_NFE , AN_NFE , Hom_NFE , Het_NFE , AC_OTH , AN_OTH , Hom_OTH , Het_OTH , AC_SAS , AN_SAS , Hom_SAS , Het_SAS ]\nops=[ self , self , self , self , self , self , self , self , self , self , self , self , self , self , self , self , self , self , self , self , self , self , self , self , self , self , self , self , self , self ]\nnames=[ nonpsych_AC_AFR , nonpsych_AN_AFR , nonpsych_Hom_AFR , nonpsych_Het_AFR , nonpsych_AC_AMR , nonpsych_AN_AMR , nonpsych_Hom_AMR , nonpsych_Het_AMR , nonpsych_AC_Adj , nonpsych_AN_Adj , nonpsych_AC_EAS , nonpsych_AN_EAS , nonpsych_Hom_EAS , nonpsych_Het_EAS , nonpsych_AC_FIN , nonpsych_AN_FIN , nonpsych_Hom_FIN , nonpsych_Het_FIN , nonpsych_AC_NFE , nonpsych_AN_NFE , nonpsych_Hom_NFE , nonpsych_Het_NFE , nonpsych_AC_OTH , nonpsych_AN_OTH , nonpsych_Hom_OTH , nonpsych_Het_OTH , nonpsych_AC_SAS , nonpsych_AN_SAS , nonpsych_Hom_SAS , nonpsych_Het_SAS ]  And a similar one for  nonTCGA . \nIn  vcfanno ,  [[postannotation]]  sections occur after any  [[annotation]]  sections and operate on the fields that are then in the \nINFO of the query. Given multiple  [[postannotation]]  sections, they will operate in the order that they appear in the file so later\nsections have access to fields created by earlier sections.  With that in mind, we create a section like this:  [[postannotation]]\nfields=[ nonpsych_AC_NFE ,  nonpsych_AN_NFE ]\nname= nonpsych_af_NFE \nop= div2 \ntype= Float   for each population and for the original superset as well as for nonpsych, nonTCGA. The script to create all this automatically is  here  Then we have a final section that calculates the maximum allele frequency among all populations:  [[postannotation]]\nfields=[ af_AFR ,  af_AMR ,  af_EAS ,  af_FIN ,  af_NFE ,  af_OTH ,  af_SAS ,  nonTCGA_af_AFR ,  nonTCGA_af_AMR ,  nonTCGA_af_EAS ,  nonTCGA_af_FIN ,  nonTCGA_af_NFE ,  nonTCGA_af_OTH ,  nonTCGA_af_SAS ,  nonpysch_af_AFR ,  nonpysch_af_AMR ,  nonpysch_af_EAS ,  nonpysch_af_FIN ,  nonpysch_af_NFE ,  nonpysch_af_OTH ,  nonpysch_af_SAS ]\nop= max \nname= max_af_ALL \ntype= Float   The entire conf file is  here  Then, the  vcfanno  command is very simple:  vcfanno -p 8 exac_combine.conf ExAC.r0.3.sites.vep.tidy.vcf.gz | bgzip -c   ExAC.r0.3.all.tidy.vcf.gz  This runs in about 15 minutes (10K variants / second) on good server with fast disk.", 
            "title": "Combine ExAC with non-psych and nonTCGA"
        }
    ]
}